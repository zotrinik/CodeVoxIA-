{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a42e0f-8f53-4649-80f2-de407bd7ee09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTS.utils.io import load_fsspec\n",
    "import torch\n",
    "def patched_load_fsspec(path, map_location=None, cache=True, **kwargs):\n",
    "    if cache:\n",
    "        return torch.load(path, map_location=map_location, weights_only=False, **kwargs)\n",
    "    else:\n",
    "        import fsspec\n",
    "        with fsspec.open(path, \"rb\") as f:\n",
    "            return torch.load(f, map_location=map_location, weights_only=False, **kwargs)\n",
    "import TTS.utils.io\n",
    "TTS.utils.io.load_fsspec = patched_load_fsspec\n",
    "\n",
    "from TTS.api import TTS\n",
    "tts = TTS(model_name=\"tts_models/multilingual/multi-dataset/xtts_v2\", progress_bar=True, gpu=False)\n",
    "print(tts.speakers)\n",
    "tts.tts_to_file(text=\"¡Hola, esto es una prueba!\", speaker=\"female-en-4\", language=\"es\", file_path=\"test_xtts.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b038fa2e-99f9-4727-9246-78669448141a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTS.api import TTS\n",
    "tts = TTS(model_name=\"tts_models/en/ljspeech/tacotron2-DDC\", progress_bar=True, gpu=False)\n",
    "tts.tts_to_file(text=\"Hello, this is a test.\", file_path=\"test_tacotron.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8d28c6-ac09-497c-a165-4d39611b9476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb587ce2-0242-498b-b1d0-0746ad181bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show torch TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e6cf663-d075-48df-9635-15cd28a4b6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 00:14:16,033 - INFO - TTS class type: <class 'type'>\n",
      "2025-05-12 00:14:16,035 - INFO - Attempting to load model: tts_models/multilingual/multi-dataset/xtts_v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.\n",
      " > Using model: xtts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 00:14:37,277 - INFO - Successfully loaded model: tts_models/multilingual/multi-dataset/xtts_v2\n",
      "2025-05-12 00:14:37,279 - ERROR - Failed to load model tts_models/multilingual/multi-dataset/xtts_v2: 'TTS' object has no attribute 'speakers'\n",
      "2025-05-12 00:14:37,281 - ERROR - Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Administrador\\AppData\\Local\\Temp\\ipykernel_1820\\2468024688.py\", line 82, in initialize_tts_model\n",
      "    logger.info(f\"Available speakers: {tts.speakers}\")\n",
      "                                       ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Administrador\\tts_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1940, in __getattr__\n",
      "    raise AttributeError(\n",
      "AttributeError: 'TTS' object has no attribute 'speakers'\n",
      "\n",
      "2025-05-12 00:14:37,282 - INFO - Falling back to model: tts_models/en/ljspeech/tacotron2-DDC\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/en/ljspeech/tacotron2-DDC is already downloaded.\n",
      " > vocoder_models/en/ljspeech/hifigan_v2 is already downloaded.\n",
      " > Using model: Tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model's reduction rate `r` is set to: 1\n",
      " > Vocoder Model: hifigan\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Generator Model: hifigan_generator\n",
      " > Discriminator Model: hifigan_discriminator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 00:14:38,471 - WARNING - Using fallback model tts_models/en/ljspeech/tacotron2-DDC, which does not support multi-speaker or multilingual voices. All characters will use the default English voice.\n",
      "2025-05-12 00:14:38,642 - INFO - Generating audio for MÍA: ¡Chicos, chicos! ¡Lo vi otra vez! El glitch ese......\n",
      "2025-05-12 00:14:38,642 - WARNING - Model does not support multi-speaker. Using default voice for MÍA.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing weight norm...\n",
      " > Text splitted to sentences.\n",
      "['¡Chicos, chicos!', '¡Lo vi otra vez!', 'El glitch ese... apareció en el comedor.', 'Una figura rara, como un fantasma digital, y luego puf, desapareció.']\n",
      "¡chicos, chicos!\n",
      " [!] Character '¡' not found in the vocabulary. Discarding it.\n",
      "el glitch ese... apareció en el comedor.\n",
      " [!] Character 'ó' not found in the vocabulary. Discarding it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 00:14:46,865 - INFO - Generated audio: audios/00_MÍA.wav\n",
      "2025-05-12 00:14:46,866 - INFO - Generating audio for ZOE: Mía, si sigues viendo fantasmas en la red AR, tal ...\n",
      "2025-05-12 00:14:46,866 - WARNING - Model does not support multi-speaker. Using default voice for ZOE.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Processing time: 8.147876977920532\n",
      " > Real-time factor: 0.5151767737289747\n",
      " > Text splitted to sentences.\n",
      "['Mía, si sigues viendo fantasmas en la red AR, tal vez deberías revisar tus lentes.', 'O dejar de tomar tanto café.']\n",
      "mía, si sigues viendo fantasmas en la red ar, tal vez deberías revisar tus lentes.\n",
      " [!] Character 'í' not found in the vocabulary. Discarding it.\n",
      "o dejar de tomar tanto café.\n",
      " [!] Character 'é' not found in the vocabulary. Discarding it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 00:14:53,293 - INFO - Generated audio: audios/01_ZOE.wav\n",
      "2025-05-12 00:14:53,293 - INFO - Generating audio for KAI: Déjala, Zoe. Mía tiene razón. Yo también vi algo r...\n",
      "2025-05-12 00:14:53,295 - WARNING - Model does not support multi-speaker. Using default voice for KAI.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Processing time: 6.360369682312012\n",
      " > Real-time factor: 0.5778104461724615\n",
      " > Text splitted to sentences.\n",
      "['Déjala, Zoe.', 'Mía tiene razón.', 'Yo también vi algo raro ayer en mi simulación.', 'Era como... una sombra que no debería estar ahí.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 00:14:59,367 - INFO - Generated audio: audios/02_KAI.wav\n",
      "2025-05-12 00:14:59,367 - INFO - Generating audio for ZOE: Espera, ¿tú también? Okay, esto ya no es una broma...\n",
      "2025-05-12 00:14:59,367 - WARNING - Model does not support multi-speaker. Using default voice for ZOE.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Processing time: 6.013552904129028\n",
      " > Real-time factor: 0.4984019482801791\n",
      " > Text splitted to sentences.\n",
      "['Espera, ¿tú también?', 'Okay, esto ya no es una broma.', 'Si hay un glitch en la red AR del campus, podría colapsar todo: exámenes, simulaciones, hasta los drones de pizza.']\n",
      "espera, ¿tú también?\n",
      " [!] Character '¿' not found in the vocabulary. Discarding it.\n",
      "espera, ¿tú también?\n",
      " [!] Character 'ú' not found in the vocabulary. Discarding it.\n",
      "si hay un glitch en la red ar del campus, podría colapsar todo, exámenes, simulaciones, hasta los drones de pizza.\n",
      " [!] Character 'á' not found in the vocabulary. Discarding it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 00:15:08,316 - INFO - Generated audio: audios/03_ZOE.wav\n",
      "2025-05-12 00:15:08,317 - INFO - Generating audio for MÍA: ¿Y si es un hacker? O... no sé, ¿una IA rebelde? ¡...\n",
      "2025-05-12 00:15:08,318 - WARNING - Model does not support multi-speaker. Using default voice for MÍA.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Processing time: 8.825683116912842\n",
      " > Real-time factor: 0.5223937871191646\n",
      " > Text splitted to sentences.\n",
      "['¿Y si es un hacker?', 'O... no sé, ¿una IA rebelde?', '¡Leí que eso pasa en las pelis!']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 00:15:12,766 - INFO - Generated audio: audios/04_MÍA.wav\n",
      "2025-05-12 00:15:12,766 - INFO - Generating audio for KAI: Mía, relaja, no estamos en Matrix. Aunque... un mi...\n",
      "2025-05-12 00:15:12,768 - WARNING - Model does not support multi-speaker. Using default voice for KAI.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Processing time: 4.395489692687988\n",
      " > Real-time factor: 0.5046683523065595\n",
      " > Text splitted to sentences.\n",
      "['Mía, relaja, no estamos en Matrix.', 'Aunque... un misterio así sería épico para mi próximo proyecto AR.', 'Imagina: El Campus Embrujado.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 00:15:19,606 - INFO - Generated audio: audios/05_KAI.wav\n",
      "2025-05-12 00:15:19,618 - INFO - Generating audio for ZOE: Tú y tus proyectos. Necesitamos encontrar el orige...\n",
      "2025-05-12 00:15:19,618 - WARNING - Model does not support multi-speaker. Using default voice for ZOE.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Processing time: 6.7558207511901855\n",
      " > Real-time factor: 0.5085686061470462\n",
      " > Text splitted to sentences.\n",
      "['Tú y tus proyectos.', 'Necesitamos encontrar el origen de este glitch antes de que el Profesor Vega nos suspenda por alterar la red.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 00:15:25,727 - INFO - Generated audio: audios/06_ZOE.wav\n",
      "2025-05-12 00:15:25,727 - INFO - Generating audio for PROFESOR VEGA: ¿Alterar la red, dicen? Interesante. Zoe, Kai, Mía...\n",
      "2025-05-12 00:15:25,730 - WARNING - Model does not support multi-speaker. Using default voice for PROFESOR VEGA.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Processing time: 6.04659366607666\n",
      " > Real-time factor: 0.5641815772553757\n",
      " > Text splitted to sentences.\n",
      "['¿Alterar la red, dicen?', 'Interesante.', 'Zoe, Kai, Mía, ¿por qué tengo reportes de un fantasma digital interrumpiendo las simulaciones del campus?']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 00:15:32,862 - INFO - Generated audio: audios/07_PROFESOR VEGA.wav\n",
      "2025-05-12 00:15:32,862 - INFO - Generating audio for MÍA: ¡No fuimos nosotros, lo juro! Solo... lo vimos....\n",
      "2025-05-12 00:15:32,862 - WARNING - Model does not support multi-speaker. Using default voice for MÍA.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Processing time: 7.07027530670166\n",
      " > Real-time factor: 0.5555461062231727\n",
      " > Text splitted to sentences.\n",
      "['¡No fuimos nosotros, lo juro!', 'Solo... lo vimos.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 00:15:35,853 - INFO - Generated audio: audios/08_MÍA.wav\n",
      "2025-05-12 00:15:35,853 - INFO - Generating audio for ZOE: Profesor, si hay un glitch, puedo rastrearlo. Pero...\n",
      "2025-05-12 00:15:35,855 - WARNING - Model does not support multi-speaker. Using default voice for ZOE.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Processing time: 2.9485599994659424\n",
      " > Real-time factor: 0.4939805797792368\n",
      " > Text splitted to sentences.\n",
      "['Profesor, si hay un glitch, puedo rastrearlo.', 'Pero necesito acceso al núcleo de la red AR.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 00:15:40,887 - INFO - Generated audio: audios/09_ZOE.wav\n",
      "2025-05-12 00:15:40,889 - INFO - Generating audio for PROFESOR VEGA: ¿Acceso al núcleo? Eso es como darle las llaves de...\n",
      "2025-05-12 00:15:40,889 - WARNING - Model does not support multi-speaker. Using default voice for PROFESOR VEGA.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Processing time: 4.958626747131348\n",
      " > Real-time factor: 0.567858358475186\n",
      " > Text splitted to sentences.\n",
      "['¿Acceso al núcleo?', 'Eso es como darle las llaves de una nave estelar a un cadete.', 'Pero... me intrigan.', 'Les doy 24 horas para encontrar ese glitch.', 'Si no, limpiarán servidores por un mes.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 00:15:50,524 - INFO - Generated audio: audios/10_PROFESOR VEGA.wav\n",
      "2025-05-12 00:15:50,526 - INFO - Generating audio for KAI: Eso suena a castigo medieval....\n",
      "2025-05-12 00:15:50,527 - WARNING - Model does not support multi-speaker. Using default voice for KAI.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Processing time: 9.54564905166626\n",
      " > Real-time factor: 0.49850686268246486\n",
      " > Text splitted to sentences.\n",
      "['Eso suena a castigo medieval.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 00:15:52,124 - INFO - Generated audio: audios/11_KAI.wav\n",
      "2025-05-12 00:15:52,126 - INFO - Generating audio for MÍA: ¿Y si el glitch no es un error? ¿Y si es... algo v...\n",
      "2025-05-12 00:15:52,126 - WARNING - Model does not support multi-speaker. Using default voice for MÍA.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Processing time: 1.5646781921386719\n",
      " > Real-time factor: 0.48642502448479746\n",
      " > Text splitted to sentences.\n",
      "['¿Y si el glitch no es un error?', '¿Y si es... algo vivo?']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 00:15:54,836 - INFO - Generated audio: audios/12_MÍA.wav\n",
      "2025-05-12 00:15:54,837 - INFO - Generating audio for ZOE: Sea lo que sea, lo voy a cazar. Kai, prepara un en...\n",
      "2025-05-12 00:15:54,838 - WARNING - Model does not support multi-speaker. Using default voice for ZOE.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Processing time: 2.6654555797576904\n",
      " > Real-time factor: 0.47917179374557356\n",
      " > Text splitted to sentences.\n",
      "['Sea lo que sea, lo voy a cazar.', 'Kai, prepara un entorno AR para atraparlo.', 'Mía, tú... intenta no romper nada.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 00:16:00,548 - INFO - Generated audio: audios/13_ZOE.wav\n",
      "2025-05-12 00:16:00,551 - INFO - Generating audio for MÍA: ¡Oye, soy útil! Puedo... grabar todo para el vlog ...\n",
      "2025-05-12 00:16:00,551 - WARNING - Model does not support multi-speaker. Using default voice for MÍA.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Processing time: 5.63813042640686\n",
      " > Real-time factor: 0.5254648335627209\n",
      " > Text splitted to sentences.\n",
      "['¡Oye, soy útil!', 'Puedo... grabar todo para el vlog del campus.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 00:16:03,920 - INFO - Generated audio: audios/14_MÍA.wav\n",
      "2025-05-12 00:16:03,920 - INFO - Generating audio for KAI: Eso, Mía, haznos virales mientras salvamos el camp...\n",
      "2025-05-12 00:16:03,922 - WARNING - Model does not support multi-speaker. Using default voice for KAI.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Processing time: 3.333513021469116\n",
      " > Real-time factor: 0.49323573466954324\n",
      " > Text splitted to sentences.\n",
      "['Eso, Mía, haznos virales mientras salvamos el campus.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 00:16:06,908 - INFO - Generated audio: audios/15_KAI.wav\n",
      "2025-05-12 00:16:06,924 - INFO - ✅ Archivo final generado: audios/escena_completa.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Processing time: 2.943063974380493\n",
      " > Real-time factor: 0.4893123464462682\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from pydub import AudioSegment\n",
    "import logging\n",
    "import traceback\n",
    "\n",
    "# Set up logging first\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Patch load_fsspec to disable weights_only for xtts_v2\n",
    "from TTS.utils.io import load_fsspec\n",
    "def patched_load_fsspec(path, map_location=None, cache=True, **kwargs):\n",
    "    if cache:\n",
    "        return torch.load(path, map_location=map_location, weights_only=False, **kwargs)\n",
    "    else:\n",
    "        import fsspec\n",
    "        with fsspec.open(path, \"rb\") as f:\n",
    "            return torch.load(f, map_location=map_location, weights_only=False, **kwargs)\n",
    "import TTS.utils.io\n",
    "TTS.utils.io.load_fsspec = patched_load_fsspec\n",
    "\n",
    "# Verify TTS import\n",
    "try:\n",
    "    from TTS.api import TTS\n",
    "    logger.info(f\"TTS class type: {type(TTS)}\")\n",
    "except ImportError as e:\n",
    "    print(f\"Failed to import TTS: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(\"audios\", exist_ok=True)\n",
    "\n",
    "# List of characters and their lines\n",
    "dialogo = [\n",
    "    (\"MÍA\", \"¡Chicos, chicos! ¡Lo vi otra vez! El glitch ese... apareció en el comedor. Una figura rara, como un fantasma digital, y luego puf, desapareció.\"),\n",
    "    (\"ZOE\", \"Mía, si sigues viendo fantasmas en la red AR, tal vez deberías revisar tus lentes. O dejar de tomar tanto café.\"),\n",
    "    (\"KAI\", \"Déjala, Zoe. Mía tiene razón. Yo también vi algo raro ayer en mi simulación. Era como... una sombra que no debería estar ahí.\"),\n",
    "    (\"ZOE\", \"Espera, ¿tú también? Okay, esto ya no es una broma. Si hay un glitch en la red AR del campus, podría colapsar todo: exámenes, simulaciones, hasta los drones de pizza.\"),\n",
    "    (\"MÍA\", \"¿Y si es un hacker? O... no sé, ¿una IA rebelde? ¡Leí que eso pasa en las pelis!\"),\n",
    "    (\"KAI\", \"Mía, relaja, no estamos en Matrix. Aunque... un misterio así sería épico para mi próximo proyecto AR. Imagina: El Campus Embrujado.\"),\n",
    "    (\"ZOE\", \"Tú y tus proyectos. Necesitamos encontrar el origen de este glitch antes de que el Profesor Vega nos suspenda por alterar la red.\"),\n",
    "    (\"PROFESOR VEGA\", \"¿Alterar la red, dicen? Interesante. Zoe, Kai, Mía, ¿por qué tengo reportes de un fantasma digital interrumpiendo las simulaciones del campus?\"),\n",
    "    (\"MÍA\", \"¡No fuimos nosotros, lo juro! Solo... lo vimos.\"),\n",
    "    (\"ZOE\", \"Profesor, si hay un glitch, puedo rastrearlo. Pero necesito acceso al núcleo de la red AR.\"),\n",
    "    (\"PROFESOR VEGA\", \"¿Acceso al núcleo? Eso es como darle las llaves de una nave estelar a un cadete. Pero... me intrigan. Les doy 24 horas para encontrar ese glitch. Si no, limpiarán servidores por un mes.\"),\n",
    "    (\"KAI\", \"Eso suena a castigo medieval.\"),\n",
    "    (\"MÍA\", \"¿Y si el glitch no es un error? ¿Y si es... algo vivo?\"),\n",
    "    (\"ZOE\", \"Sea lo que sea, lo voy a cazar. Kai, prepara un entorno AR para atraparlo. Mía, tú... intenta no romper nada.\"),\n",
    "    (\"MÍA\", \"¡Oye, soy útil! Puedo... grabar todo para el vlog del campus.\"),\n",
    "    (\"KAI\", \"Eso, Mía, haznos virales mientras salvamos el campus.\")\n",
    "]\n",
    "\n",
    "# Assign voices to characters\n",
    "personajes_voces = {\n",
    "    \"MÍA\": \"tts_models/multilingual/multi-dataset/xtts_v2\",\n",
    "    \"ZOE\": \"tts_models/multilingual/multi-dataset/xtts_v2\",\n",
    "    \"KAI\": \"tts_models/multilingual/multi-dataset/xtts_v2\",\n",
    "    \"PROFESOR VEGA\": \"tts_models/multilingual/multi-dataset/xtts_v2\"\n",
    "}\n",
    "\n",
    "# Placeholder speaker IDs (update after checking tts.speakers)\n",
    "voces_ids = {\n",
    "    \"MÍA\": \"female-en-4\",\n",
    "    \"ZOE\": \"female-en-3\",\n",
    "    \"KAI\": \"male-en-3\",\n",
    "    \"PROFESOR VEGA\": \"male-en-1\"\n",
    "}\n",
    "\n",
    "# Fallback model\n",
    "FALLBACK_MODEL = \"tts_models/en/ljspeech/tacotron2-DDC\"\n",
    "\n",
    "def initialize_tts_model(model_name, gpu=False):\n",
    "    \"\"\"Initialize TTS model with error handling and fallback.\"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Attempting to load model: {model_name}\")\n",
    "        tts = TTS(model_name=model_name, progress_bar=True, gpu=gpu)\n",
    "        logger.info(f\"Successfully loaded model: {model_name}\")\n",
    "        # Log available speakers and multilingual support\n",
    "        if hasattr(tts, \"is_multi_speaker\") and tts.is_multi_speaker:\n",
    "            logger.info(f\"Available speakers: {tts.speakers}\")\n",
    "        if hasattr(tts, \"is_multi_lingual\") and tts.is_multi_lingual:\n",
    "            logger.info(\"Model supports multilingual input\")\n",
    "        else:\n",
    "            logger.info(\"Model is not multilingual\")\n",
    "        return tts\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load model {model_name}: {str(e)}\")\n",
    "        logger.error(traceback.format_exc())\n",
    "        logger.info(f\"Falling back to model: {FALLBACK_MODEL}\")\n",
    "        try:\n",
    "            tts = TTS(model_name=FALLBACK_MODEL, progress_bar=True, gpu=gpu)\n",
    "            logger.warning(f\"Using fallback model {FALLBACK_MODEL}, which does not support multi-speaker or multilingual voices. All characters will use the default English voice.\")\n",
    "            return tts\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load fallback model {FALLBACK_MODEL}: {str(e)}\")\n",
    "            raise RuntimeError(\"Could not initialize any TTS model.\")\n",
    "\n",
    "# Initialize the model\n",
    "try:\n",
    "    tts = initialize_tts_model(personajes_voces[\"MÍA\"], gpu=False)\n",
    "except RuntimeError as e:\n",
    "    logger.error(str(e))\n",
    "    raise\n",
    "\n",
    "# Generate audio for each line\n",
    "audio_parts = []\n",
    "for i, (personaje, texto) in enumerate(dialogo):\n",
    "    output_file = f\"audios/{i:02d}_{personaje}.wav\"\n",
    "    try:\n",
    "        logger.info(f\"Generating audio for {personaje}: {texto[:50]}...\")\n",
    "        if hasattr(tts, \"is_multi_speaker\") and tts.is_multi_speaker:\n",
    "            if voces_ids[personaje] in tts.speakers:\n",
    "                # Use language only for multilingual models\n",
    "                if hasattr(tts, \"is_multi_lingual\") and tts.is_multi_lingual:\n",
    "                    tts.tts_to_file(text=texto, speaker=voces_ids[personaje], language=\"es\", file_path=output_file)\n",
    "                else:\n",
    "                    tts.tts_to_file(text=texto, speaker=voces_ids[personaje], file_path=output_file)\n",
    "            else:\n",
    "                logger.warning(f\"Speaker {voces_ids[personaje]} not found for {personaje}. Using default voice.\")\n",
    "                if hasattr(tts, \"is_multi_lingual\") and tts.is_multi_lingual:\n",
    "                    tts.tts_to_file(text=texto, language=\"es\", file_path=output_file)\n",
    "                else:\n",
    "                    tts.tts_to_file(text=texto, file_path=output_file)\n",
    "        else:\n",
    "            logger.warning(f\"Model does not support multi-speaker. Using default voice for {personaje}.\")\n",
    "            if hasattr(tts, \"is_multi_lingual\") and tts.is_multi_lingual:\n",
    "                tts.tts_to_file(text=texto, language=\"es\", file_path=output_file)\n",
    "            else:\n",
    "                tts.tts_to_file(text=texto, file_path=output_file)\n",
    "        audio_parts.append(AudioSegment.from_wav(output_file))\n",
    "        logger.info(f\"Generated audio: {output_file}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to generate audio for {personaje}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Combine all audio parts\n",
    "if audio_parts:\n",
    "    narracion_completa = sum(audio_parts)\n",
    "    output_final = \"audios/escena_completa.wav\"\n",
    "    narracion_completa.export(output_final, format=\"wav\")\n",
    "    logger.info(f\"✅ Archivo final generado: {output_final}\")\n",
    "else:\n",
    "    logger.error(\"No audio parts were generated. Check logs for errors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07ff17a6-2fd3-466c-9ff2-857d855de292",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 00:20:36,401 - INFO - Generating audio for MÍA: ¡Chicos, chicos! ¡Lo vi otra vez! El glitch ese......\n",
      "2025-05-12 00:20:49,810 - INFO - Generated audio: audios/00_MÍA.wav\n",
      "2025-05-12 00:20:49,810 - INFO - Generating audio for ZOE: Mía, si sigues viendo fantasmas en la red AR, tal ...\n",
      "2025-05-12 00:20:51,803 - INFO - Generated audio: audios/01_ZOE.wav\n",
      "2025-05-12 00:20:51,804 - INFO - Generating audio for KAI: Déjala, Zoe. Mía tiene razón. Yo también vi algo r...\n",
      "2025-05-12 00:20:54,887 - INFO - Generated audio: audios/02_KAI.wav\n",
      "2025-05-12 00:20:54,887 - INFO - Generating audio for ZOE: Espera, ¿tú también? Okay, esto ya no es una broma...\n",
      "2025-05-12 00:20:59,003 - INFO - Generated audio: audios/03_ZOE.wav\n",
      "2025-05-12 00:20:59,003 - INFO - Generating audio for MÍA: ¿Y si es un hacker? O... no sé, ¿una IA rebelde? ¡...\n",
      "2025-05-12 00:20:59,659 - INFO - Generated audio: audios/04_MÍA.wav\n",
      "2025-05-12 00:20:59,659 - INFO - Generating audio for KAI: Mía, relaja, no estamos en Matrix. Aunque... un mi...\n",
      "2025-05-12 00:21:02,948 - INFO - Generated audio: audios/05_KAI.wav\n",
      "2025-05-12 00:21:02,948 - INFO - Generating audio for ZOE: Tú y tus proyectos. Necesitamos encontrar el orige...\n",
      "2025-05-12 00:21:04,613 - INFO - Generated audio: audios/06_ZOE.wav\n",
      "2025-05-12 00:21:04,613 - INFO - Generating audio for PROFESOR VEGA: ¿Alterar la red, dicen? Interesante. Zoe, Kai, Mía...\n",
      "2025-05-12 00:21:08,226 - INFO - Generated audio: audios/07_PROFESOR VEGA.wav\n",
      "2025-05-12 00:21:08,226 - INFO - Generating audio for MÍA: ¡No fuimos nosotros, lo juro! Solo... lo vimos....\n",
      "2025-05-12 00:21:09,049 - INFO - Generated audio: audios/08_MÍA.wav\n",
      "2025-05-12 00:21:09,050 - INFO - Generating audio for ZOE: Profesor, si hay un glitch, puedo rastrearlo. Pero...\n",
      "2025-05-12 00:21:09,990 - INFO - Generated audio: audios/09_ZOE.wav\n",
      "2025-05-12 00:21:09,990 - INFO - Generating audio for PROFESOR VEGA: ¿Acceso al núcleo? Eso es como darle las llaves de...\n",
      "2025-05-12 00:21:14,416 - INFO - Generated audio: audios/10_PROFESOR VEGA.wav\n",
      "2025-05-12 00:21:14,416 - INFO - Generating audio for KAI: Eso suena a castigo medieval....\n",
      "2025-05-12 00:21:15,070 - INFO - Generated audio: audios/11_KAI.wav\n",
      "2025-05-12 00:21:15,070 - INFO - Generating audio for MÍA: ¿Y si el glitch no es un error? ¿Y si es... algo v...\n",
      "2025-05-12 00:21:15,917 - INFO - Generated audio: audios/12_MÍA.wav\n",
      "2025-05-12 00:21:15,917 - INFO - Generating audio for ZOE: Sea lo que sea, lo voy a cazar. Kai, prepara un en...\n",
      "2025-05-12 00:21:19,300 - INFO - Generated audio: audios/13_ZOE.wav\n",
      "2025-05-12 00:21:19,301 - INFO - Generating audio for MÍA: ¡Oye, soy útil! Puedo... grabar todo para el vlog ...\n",
      "2025-05-12 00:21:20,068 - INFO - Generated audio: audios/14_MÍA.wav\n",
      "2025-05-12 00:21:20,068 - INFO - Generating audio for KAI: Eso, Mía, haznos virales mientras salvamos el camp...\n",
      "2025-05-12 00:21:20,870 - INFO - Generated audio: audios/15_KAI.wav\n",
      "2025-05-12 00:21:20,940 - INFO - ✅ Archivo final generado: audios/escena_completa.wav\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from gtts import gTTS\n",
    "from pydub import AudioSegment\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(\"audios\", exist_ok=True)\n",
    "\n",
    "# List of characters and their lines\n",
    "dialogo = [\n",
    "    (\"MÍA\", \"¡Chicos, chicos! ¡Lo vi otra vez! El glitch ese... apareció en el comedor. Una figura rara, como un fantasma digital, y luego puf, desapareció.\"),\n",
    "    (\"ZOE\", \"Mía, si sigues viendo fantasmas en la red AR, tal vez deberías revisar tus lentes. O dejar de tomar tanto café.\"),\n",
    "    (\"KAI\", \"Déjala, Zoe. Mía tiene razón. Yo también vi algo raro ayer en mi simulación. Era como... una sombra que no debería estar ahí.\"),\n",
    "    (\"ZOE\", \"Espera, ¿tú también? Okay, esto ya no es una broma. Si hay un glitch en la red AR del campus, podría colapsar todo: exámenes, simulaciones, hasta los drones de pizza.\"),\n",
    "    (\"MÍA\", \"¿Y si es un hacker? O... no sé, ¿una IA rebelde? ¡Leí que eso pasa en las pelis!\"),\n",
    "    (\"KAI\", \"Mía, relaja, no estamos en Matrix. Aunque... un misterio así sería épico para mi próximo proyecto AR. Imagina: El Campus Embrujado.\"),\n",
    "    (\"ZOE\", \"Tú y tus proyectos. Necesitamos encontrar el origen de este glitch antes de que el Profesor Vega nos suspenda por alterar la red.\"),\n",
    "    (\"PROFESOR VEGA\", \"¿Alterar la red, dicen? Interesante. Zoe, Kai, Mía, ¿por qué tengo reportes de un fantasma digital interrumpiendo las simulaciones del campus?\"),\n",
    "    (\"MÍA\", \"¡No fuimos nosotros, lo juro! Solo... lo vimos.\"),\n",
    "    (\"ZOE\", \"Profesor, si hay un glitch, puedo rastrearlo. Pero necesito acceso al núcleo de la red AR.\"),\n",
    "    (\"PROFESOR VEGA\", \"¿Acceso al núcleo? Eso es como darle las llaves de una nave estelar a un cadete. Pero... me intrigan. Les doy 24 horas para encontrar ese glitch. Si no, limpiarán servidores por un mes.\"),\n",
    "    (\"KAI\", \"Eso suena a castigo medieval.\"),\n",
    "    (\"MÍA\", \"¿Y si el glitch no es un error? ¿Y si es... algo vivo?\"),\n",
    "    (\"ZOE\", \"Sea lo que sea, lo voy a cazar. Kai, prepara un entorno AR para atraparlo. Mía, tú... intenta no romper nada.\"),\n",
    "    (\"MÍA\", \"¡Oye, soy útil! Puedo... grabar todo para el vlog del campus.\"),\n",
    "    (\"KAI\", \"Eso, Mía, haznos virales mientras salvamos el campus.\")\n",
    "]\n",
    "\n",
    "# Voice variation settings (simulate different voices)\n",
    "voice_settings = {\n",
    "    \"MÍA\": {\"slow\": False, \"pitch_shift\": 2},  # Voz más aguda\n",
    "    \"ZOE\": {\"slow\": False, \"pitch_shift\": -1},  # Voz ligeramente más grave\n",
    "    \"KAI\": {\"slow\": True, \"pitch_shift\": -4},   # Voz más lenta y grave\n",
    "    \"PROFESOR VEGA\": {\"slow\": True, \"pitch_shift\": -6}  # Voz muy grave\n",
    "}\n",
    "\n",
    "# Generate audio for each line\n",
    "audio_parts = []\n",
    "for i, (personaje, texto) in enumerate(dialogo):\n",
    "    output_file = f\"audios/{i:02d}_{personaje}.mp3\"\n",
    "    try:\n",
    "        logger.info(f\"Generating audio for {personaje}: {texto[:50]}...\")\n",
    "        tts = gTTS(text=texto, lang=\"es\", slow=voice_settings[personaje][\"slow\"])\n",
    "        tts.save(output_file)\n",
    "        # Convert MP3 to WAV and apply pitch shift\n",
    "        audio = AudioSegment.from_mp3(output_file)\n",
    "        # Apply pitch shift (semitones)\n",
    "        pitch_shifted = audio._spawn(audio.raw_data, overrides={\n",
    "            \"frame_rate\": int(audio.frame_rate * (2.0 ** (voice_settings[personaje][\"pitch_shift\"] / 12.0)))\n",
    "        })\n",
    "        wav_file = output_file.replace(\".mp3\", \".wav\")\n",
    "        pitch_shifted.export(wav_file, format=\"wav\")\n",
    "        audio_parts.append(AudioSegment.from_wav(wav_file))\n",
    "        logger.info(f\"Generated audio: {wav_file}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to generate audio for {personaje}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Combine all audio parts\n",
    "if audio_parts:\n",
    "    narracion_completa = sum(audio_parts)\n",
    "    output_final = \"audios/escena_completa.wav\"\n",
    "    narracion_completa.export(output_final, format=\"wav\")\n",
    "    logger.info(f\"✅ Archivo final generado: {output_final}\")\n",
    "else:\n",
    "    logger.error(\"No audio parts were generated. Check logs for errors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e524878-3229-4698-840c-7171962496b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
